# -*- coding: utf-8 -*-
"""Data1202-GroupProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15C7QkKWXNzjLbO8oIgdIEZXecMuk4j99

**DATA UPLOAD**
"""

from google.colab import files
uploaded = files.upload()

"""
**IMPORT LIBRARIES**

"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

"""**DATASET DEFINITION**"""

#reading the required data files
df = pd.read_csv('dataset.csv')

# Print the column names to see what columns are available
print(df.columns)

"""**EXTRACTION OF INFORMATION - # OF INSTANCES, # OF FEATURES, # OF INSTANCES FROM EACH CLASS**"""

# Number of instances
num_instances = df.shape[0]

# Number of features
num_features = df.shape[1] - 1  # Subtracting the classification column

# Number of instances from each class
class_distribution = df['classification'].value_counts()

# Displaying the results
print(f"Number of instances: {num_instances}")
print(f"Number of features: {num_features}")
print(f"Number of instances from each class:\n{class_distribution}")

"""**TESTING AND TRAINING DATA SPLIT**"""

from sklearn.model_selection import train_test_split

df = pd.read_csv('dataset.csv')

# Features and target variable
X = df.drop(columns=['classification'])  # Features
y = df['classification']                 # Target

# Split the data while maintaining the balance of classes
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Verifying the balance in the training and testing sets
train_class_distribution = y_train.value_counts()
test_class_distribution = y_test.value_counts()

train_class_distribution, test_class_distribution

"""**EXPLORATORY DATA ANALYSIS (EDA)**"""

# Combine X_test and y_test for easier analysis
df = pd.concat([X_test, y_test], axis=1)

df.head()

df.dtypes

df.describe()

#Missing Values
df.isnull().sum()

"""**UNIVARIATE ANALYSIS**"""

class_distribution = df['classification'].value_counts()
print(class_distribution)

# Plotting the class distribution
class_distribution.plot(kind='bar', title='Class Distribution', color='Purple')
plt.xlabel('Class')
plt.ylabel('Number of Instances')
plt.show()

print("\nFeature Distributions:")
numeric_features = df.columns.tolist()

# Plotting the distribution of selected features
df.hist(figsize=(15, 12), bins=20, color='purple')
plt.tight_layout()
plt.show()

"""**BIVARIATE ANALYSIS**"""

print("\nBox Plots:")
for feature in df.columns:  # Adjust this line according to your actual feature loop
    plt.figure(figsize=(4,2))
    sns.boxplot(x='classification', y=feature, data=df, hue='classification', palette=["#800080", "#FFA500"], legend=False)  # Purple and Orange
    plt.title(f'Boxplot of {feature} by Classification')
    plt.show()

# Select only numeric columns for correlation matrix
numeric_df = df.select_dtypes(include=['float64', 'int64'])

# Calculate the correlation matrix
correlation_matrix = numeric_df.corr()

# Plotting the correlation matrix
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=False, cmap='magma', linewidths=0, linecolor=None)
plt.title('Correlation Matrix')
plt.show()

# Select a subset of features
selected_features = ['millisecond', 'task_size', 'usage_counter', 'classification']

# Sample the data
sampled_df = df[selected_features].sample(frac=0.1, random_state=42)

# Generate the pair plot
sns.pairplot(sampled_df, hue='classification')
plt.show()

"""**MACHINE LEARNING CLASSIFIERS - CREATION, TRAINING, TESTING AND CONFUSION MATRIX**"""

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

# X_train, X_test, y_train, y_test are already defined above

# Step 1: Select only numeric columns
numeric_columns = X_train.select_dtypes(include=['float64', 'int64']).columns

# Step 2: Scale only the numeric columns
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train[numeric_columns])
X_test_scaled = scaler.transform(X_test[numeric_columns])

"""**Classifier 1 - Logistics Regression**"""

#Create the Model
logistic_regression = LogisticRegression(random_state=0)

# Train the model
logistic_regression.fit(X_train_scaled, y_train)

# Predictions and Evaluation for Logistic Regression
y_pred_logistic = logistic_regression.predict(X_test_scaled)

# Display Report
print("Logistic Regression")
print("Accuracy:", accuracy_score(y_test, y_pred_logistic))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_logistic))
print("Classification Report:\n", classification_report(y_test, y_pred_logistic))
print("-" * 50)

# Create a confusion matrix Plot
cm = confusion_matrix(y_test, y_pred_logistic)

# Plotting the confusion matrix as a heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='magma', xticklabels=True, yticklabels=True)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - Logistic Regression')
plt.show()

"""**Classifier 2 - Decision Tree**"""

#Create the Model
decision_tree = DecisionTreeClassifier(random_state=0)

# Train the model
decision_tree.fit(X_train_scaled, y_train)

# Predictions and Evaluation for Decision Tree
y_pred_dt = decision_tree.predict(X_test_scaled)

# Display Report
print("Decision Tree")
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))
print("Classification Report:\n", classification_report(y_test, y_pred_dt))
print("-" * 50)

# Create a confusion matrix Plot
cm = confusion_matrix(y_test, y_pred_dt)

# Plotting the confusion matrix as a heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='magma', xticklabels=True, yticklabels=True)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - Decision Tree')
plt.show()

"""**Classifier 3 - Support Vector Machine (SVM)**"""

#Create the Model
svm = SVC(random_state=0)

# Train the model
svm.fit(X_train_scaled, y_train)

# Predictions and Evaluation for Support Vector Machine
y_pred_svm = svm.predict(X_test_scaled)

# Display Report
print("Support Vector Machine - SVM")
print("Accuracy:", accuracy_score(y_test, y_pred_svm))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_svm))
print("Classification Report:\n", classification_report(y_test, y_pred_svm))
print("-" * 50)

# Create a confusion matrix Plot
cm = confusion_matrix(y_test, y_pred_svm)

# Plotting the confusion matrix as a heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='magma', xticklabels=True, yticklabels=True)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - Support Vector Machine')

"""**Classifier 4 - Neural Network (NN)**"""

#Create the Model
neural_network = MLPClassifier(random_state=0, max_iter=300)

# Train the model
neural_network.fit(X_train_scaled, y_train)

# Predictions and Evaluation for Neural Network
y_pred_nn = neural_network.predict(X_test_scaled)

# Display Report
print("Neural Network")
print("Accuracy:", accuracy_score(y_test, y_pred_nn))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_nn))
print("Classification Report:\n", classification_report(y_test, y_pred_nn))
print("-" * 50)

# Create a confusion matrix Plot
cm = confusion_matrix(y_test, y_pred_nn)

# Plotting the confusion matrix as a heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='magma', xticklabels=True, yticklabels=True)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - Neural Network')

"""**Classifier 5 - K-Nearest Neighbors (KNN)**"""

#Create the Model
knn = KNeighborsClassifier(n_neighbors=5)

# Train the model
knn.fit(X_train_scaled, y_train)

# Predictions and Evaluation for K-Nearest Neighbors -KNN
y_pred_knn = knn.predict(X_test_scaled)


# Display Report
print("K-Nearest Neighbors -KNN")
print("Accuracy:", accuracy_score(y_test, y_pred_knn))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_knn))
print("Classification Report:\n", classification_report(y_test, y_pred_knn))
print("-" * 50)

# Create a confusion matrix Plot
cm = confusion_matrix(y_test, y_pred_knn)

# Plotting the confusion matrix as a heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='magma', xticklabels=True, yticklabels=True)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - K-Nearest Neighbors')

from google.colab import drive,files


!cp /content/drive/MyDrive/ColabNotebooksPrj/Data1202-GroupProject.ipynb /content/

# Convert the notebook to HTML
!jupyter nbconvert --to html Data1202-GroupProject.ipynb

# Download the HTML file
html_filename = 'Data1202-GroupProject.html'
files.download(html_filename)